{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ast\n",
    "import gc\n",
    "import pickle\n",
    "import os\n",
    "import random\n",
    "import re\n",
    "\n",
    "import optuna\n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "from optuna.trial import TrialState\n",
    "from sklearn.metrics import f1_score\n",
    "from torch.optim import lr_scheduler\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "from data_preparation import (\n",
    "    get_embeddings, \n",
    "    make_features_transformers,\n",
    "    make_features_cnn,\n",
    "    train_valid_test_split\n",
    ")\n",
    "from inference import (\n",
    "    predict,\n",
    "    predict_sample,\n",
    "    test_model\n",
    ")\n",
    "from training import (\n",
    "    ad_hoc_train,\n",
    "    create_labels, \n",
    "    get_loaders,\n",
    "    train_model,\n",
    "    train_parametrized\n",
    ")\n",
    "\n",
    "SEED = 42\n",
    "np.random.seed(SEED)\n",
    "random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "torch.cuda.manual_seed(SEED)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False\n",
    "os.environ[\"PYTHONHASHSEED\"] = str(SEED)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "products = pd.read_parquet('train.parquet')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Some Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>product_id</th>\n",
       "      <th>category_id</th>\n",
       "      <th>sale</th>\n",
       "      <th>shop_id</th>\n",
       "      <th>shop_title</th>\n",
       "      <th>rating</th>\n",
       "      <th>text_fields</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>56718</th>\n",
       "      <td>1159722</td>\n",
       "      <td>14233</td>\n",
       "      <td>False</td>\n",
       "      <td>25374</td>\n",
       "      <td>COMFY wear</td>\n",
       "      <td>5.0</td>\n",
       "      <td>{\"title\": \"Хлопковые женские трусы, подарок на...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81326</th>\n",
       "      <td>1105829</td>\n",
       "      <td>11826</td>\n",
       "      <td>False</td>\n",
       "      <td>26591</td>\n",
       "      <td>Ежевика</td>\n",
       "      <td>5.0</td>\n",
       "      <td>{\"title\": \"Коврик силиконовый для раскатки тес...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38250</th>\n",
       "      <td>443799</td>\n",
       "      <td>13297</td>\n",
       "      <td>False</td>\n",
       "      <td>14885</td>\n",
       "      <td>МультиДом</td>\n",
       "      <td>5.0</td>\n",
       "      <td>{\"title\": \"Эко-мешочек сетка 22х25см\", \"descri...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       product_id  category_id   sale  shop_id  shop_title  rating  \\\n",
       "56718     1159722        14233  False    25374  COMFY wear     5.0   \n",
       "81326     1105829        11826  False    26591     Ежевика     5.0   \n",
       "38250      443799        13297  False    14885   МультиДом     5.0   \n",
       "\n",
       "                                             text_fields  \n",
       "56718  {\"title\": \"Хлопковые женские трусы, подарок на...  \n",
       "81326  {\"title\": \"Коврик силиконовый для раскатки тес...  \n",
       "38250  {\"title\": \"Эко-мешочек сетка 22х25см\", \"descri...  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "products.sample(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(91120, 7)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "products.shape"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have no missing values in our data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "product_id     0\n",
       "category_id    0\n",
       "sale           0\n",
       "shop_id        0\n",
       "shop_title     0\n",
       "rating         0\n",
       "text_fields    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "products.isnull().sum()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Overall we have 874 different categories.\n",
    "\n",
    "Some of them are with small number of samples in them.\n",
    "\n",
    "Classes are dibalanced."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11937    6590\n",
       "14922    3709\n",
       "13651    1463\n",
       "13143    1460\n",
       "12980    1222\n",
       "         ... \n",
       "12808       2\n",
       "12901       1\n",
       "11549       1\n",
       "11875       1\n",
       "12836       1\n",
       "Name: category_id, Length: 874, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "products.category_id.value_counts()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Text Fields"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's unpack fileds to an appropriate way."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'title': 'Зарядный кабель Borofone BX1 Lightning для айфон, 1м',\n",
       " 'description': '<p><span style=\"background-color: transparent; color: rgb(0, 26, 52);\">Зарядный кабель Borofone BX1 подходит для зарядки всех гаджетов и аксессуаров с разъемом </span>Lightning.</p><p><span style=\"color: rgb(0, 26, 52); background-color: transparent;\">Поддерживает быструю зарядку.</span></p><p><span style=\"color: rgb(0, 26, 52); background-color: transparent;\">Подходит для передачи данных.</span></p>',\n",
       " 'attributes': ['Длина: 1м',\n",
       "  'Разъем: Lightning',\n",
       "  'Подерживает быструю зарядку',\n",
       "  'Максимальный ток: 2.0А',\n",
       "  'Для зарядки и синхронизации данных',\n",
       "  'Вес: 22 г.'],\n",
       " 'custom_characteristics': {},\n",
       " 'defined_characteristics': {'Цвет': ['Черный', 'Белый']},\n",
       " 'filters': {'Цвет': ['Белый', 'Черный']}}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ast.literal_eval(products.iloc[0]['text_fields'])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I will take `title`, `description`, and concatenated `attributes` field."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('Зарядный кабель Borofone BX1 Lightning для айфон, 1м',\n",
       " 'Зарядный кабель Borofone BX1 подходит для зарядки всех гаджетов и аксессуаров с разъемом Lightning.Поддерживает быструю зарядку.Подходит для передачи данных.',\n",
       " 'Длина: 1м. Разъем: Lightning. Подерживает быструю зарядку. Максимальный ток: 2.0А. Для зарядки и синхронизации данных. Вес: 22 г.')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def extract_text(text_field: str):\n",
    "    content_dict = ast.literal_eval(text_field)\n",
    "    title = content_dict['title']\n",
    "    description = re.sub(\"<[^\\>]*>\", '', content_dict['description'])\n",
    "    attributes = '. '.join(content_dict['attributes'])\n",
    "\n",
    "    return title, description, attributes\n",
    "\n",
    "extract_text(products.iloc[0]['text_fields'])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's extract needed text fields."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>description</th>\n",
       "      <th>attributes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Зарядный кабель Borofone BX1 Lightning для айф...</td>\n",
       "      <td>Зарядный кабель Borofone BX1 подходит для заря...</td>\n",
       "      <td>Длина: 1м. Разъем: Lightning. Подерживает быст...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Трусы Sela</td>\n",
       "      <td>Трусы-слипы из эластичного бесшовного трикотаж...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Гуашь \"ЮНЫЙ ВОЛШЕБНИК\", 12 цветов по 35 мл, БО...</td>\n",
       "      <td>Гуашь высшего качества ЮНЛАНДИЯ поможет создат...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Колба для кальяна Крафт (разные цвета)</td>\n",
       "      <td>Универсальная колба для кальяна Craft подходит...</td>\n",
       "      <td>Материал: стекло. Внутренний диаметр: 45 мм . ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Пижама женская, однотонная с шортами</td>\n",
       "      <td>Лёгкая ткань! Комфортная посадка! Идеальная дл...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title  \\\n",
       "0  Зарядный кабель Borofone BX1 Lightning для айф...   \n",
       "1                                         Трусы Sela   \n",
       "2  Гуашь \"ЮНЫЙ ВОЛШЕБНИК\", 12 цветов по 35 мл, БО...   \n",
       "3             Колба для кальяна Крафт (разные цвета)   \n",
       "4               Пижама женская, однотонная с шортами   \n",
       "\n",
       "                                         description  \\\n",
       "0  Зарядный кабель Borofone BX1 подходит для заря...   \n",
       "1  Трусы-слипы из эластичного бесшовного трикотаж...   \n",
       "2  Гуашь высшего качества ЮНЛАНДИЯ поможет создат...   \n",
       "3  Универсальная колба для кальяна Craft подходит...   \n",
       "4  Лёгкая ткань! Комфортная посадка! Идеальная дл...   \n",
       "\n",
       "                                          attributes  \n",
       "0  Длина: 1м. Разъем: Lightning. Подерживает быст...  \n",
       "1                                                     \n",
       "2                                                     \n",
       "3  Материал: стекло. Внутренний диаметр: 45 мм . ...  \n",
       "4                                                     "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "titles, desciptions, attributes = zip(*products['text_fields'].apply(extract_text))\n",
    "text_data = pd.DataFrame({'title': titles, 'description': desciptions, 'attributes': attributes})\n",
    "text_data.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Very few products does not contain `description`.\n",
    "\n",
    "About of one quarter of products does not contain `attributes`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "title              0\n",
       "description     1538\n",
       "attributes     26131\n",
       "dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(text_data == '').sum()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset Creation"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's combine columns which will be needed for model traing.\n",
    "\n",
    "I will not take take `shop_id` as it is ordinally encoded. Ordinal encoding does not suit such categorical data as shop identifier. Instead of `shop_id` I want to use embedded `shop_title`.\n",
    "\n",
    "Binary flag `sale` is not very helpful in prediction across 874 classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>product_id</th>\n",
       "      <th>category_id</th>\n",
       "      <th>shop_title</th>\n",
       "      <th>rating</th>\n",
       "      <th>title</th>\n",
       "      <th>description</th>\n",
       "      <th>attributes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>325286</td>\n",
       "      <td>12171</td>\n",
       "      <td>Aksik</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Зарядный кабель Borofone BX1 Lightning для айф...</td>\n",
       "      <td>Зарядный кабель Borofone BX1 подходит для заря...</td>\n",
       "      <td>Длина: 1м. Разъем: Lightning. Подерживает быст...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>888134</td>\n",
       "      <td>14233</td>\n",
       "      <td>Sela</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Трусы Sela</td>\n",
       "      <td>Трусы-слипы из эластичного бесшовного трикотаж...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1267173</td>\n",
       "      <td>13429</td>\n",
       "      <td>ЮНЛАНДИЯ канцтовары</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Гуашь \"ЮНЫЙ ВОЛШЕБНИК\", 12 цветов по 35 мл, БО...</td>\n",
       "      <td>Гуашь высшего качества ЮНЛАНДИЯ поможет создат...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1416943</td>\n",
       "      <td>2789</td>\n",
       "      <td>вася-nicotine</td>\n",
       "      <td>4.0</td>\n",
       "      <td>Колба для кальяна Крафт (разные цвета)</td>\n",
       "      <td>Универсальная колба для кальяна Craft подходит...</td>\n",
       "      <td>Материал: стекло. Внутренний диаметр: 45 мм . ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1058275</td>\n",
       "      <td>12834</td>\n",
       "      <td>Lim Market</td>\n",
       "      <td>4.6</td>\n",
       "      <td>Пижама женская, однотонная с шортами</td>\n",
       "      <td>Лёгкая ткань! Комфортная посадка! Идеальная дл...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   product_id  category_id           shop_title  rating  \\\n",
       "0      325286        12171                Aksik     5.0   \n",
       "1      888134        14233                 Sela     5.0   \n",
       "2     1267173        13429  ЮНЛАНДИЯ канцтовары     5.0   \n",
       "3     1416943         2789        вася-nicotine     4.0   \n",
       "4     1058275        12834           Lim Market     4.6   \n",
       "\n",
       "                                               title  \\\n",
       "0  Зарядный кабель Borofone BX1 Lightning для айф...   \n",
       "1                                         Трусы Sela   \n",
       "2  Гуашь \"ЮНЫЙ ВОЛШЕБНИК\", 12 цветов по 35 мл, БО...   \n",
       "3             Колба для кальяна Крафт (разные цвета)   \n",
       "4               Пижама женская, однотонная с шортами   \n",
       "\n",
       "                                         description  \\\n",
       "0  Зарядный кабель Borofone BX1 подходит для заря...   \n",
       "1  Трусы-слипы из эластичного бесшовного трикотаж...   \n",
       "2  Гуашь высшего качества ЮНЛАНДИЯ поможет создат...   \n",
       "3  Универсальная колба для кальяна Craft подходит...   \n",
       "4  Лёгкая ткань! Комфортная посадка! Идеальная дл...   \n",
       "\n",
       "                                          attributes  \n",
       "0  Длина: 1м. Разъем: Lightning. Подерживает быст...  \n",
       "1                                                     \n",
       "2                                                     \n",
       "3  Материал: стекло. Внутренний диаметр: 45 мм . ...  \n",
       "4                                                     "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = pd.concat(\n",
    "    [\n",
    "        products[['product_id', 'category_id', 'shop_title', 'rating']].reset_index(drop=True), \n",
    "        text_data.reset_index(drop=True)\n",
    "    ], \n",
    "    axis=1\n",
    ")\n",
    "dataset.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Test Split"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I will divide dataset into `stratified` train valid test split to keep classes balance. I will perform division once and use it for evaluation of each model.\n",
    "\n",
    "There are some categories which have very few products in them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11937    6590\n",
       "14922    3709\n",
       "13651    1463\n",
       "13143    1460\n",
       "12980    1222\n",
       "         ... \n",
       "12808       2\n",
       "12901       1\n",
       "11549       1\n",
       "11875       1\n",
       "12836       1\n",
       "Name: category_id, Length: 874, dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "categories_frequences = dataset['category_id'].value_counts()\n",
    "categories_frequences"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I want to have at least two instances of every `product_id` in train set and one in each valid and test. There some `product ids` which has less products than needed. I will keep these products only in train set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rare_categories = categories_frequences < 4\n",
    "number_of_rare_categories = rare_categories.sum()\n",
    "number_of_rare_categories"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I will apply train, valid, test split on frequent categories."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "frequent_categories_ids = categories_frequences[~rare_categories].index\n",
    "dataset_fr = dataset[dataset['category_id'].isin(frequent_categories_ids)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_fr = train_valid_test_split(\n",
    "    dataset_fr, \n",
    "    val_size=0.1, \n",
    "    test_size=0.1,\n",
    "    stratify_col='category_id'\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now I have stratified split of the data for train, validation and test right in the table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>product_id</th>\n",
       "      <th>category_id</th>\n",
       "      <th>shop_title</th>\n",
       "      <th>rating</th>\n",
       "      <th>title</th>\n",
       "      <th>description</th>\n",
       "      <th>attributes</th>\n",
       "      <th>train</th>\n",
       "      <th>valid</th>\n",
       "      <th>test</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>325286</td>\n",
       "      <td>12171</td>\n",
       "      <td>Aksik</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Зарядный кабель Borofone BX1 Lightning для айф...</td>\n",
       "      <td>Зарядный кабель Borofone BX1 подходит для заря...</td>\n",
       "      <td>Длина: 1м. Разъем: Lightning. Подерживает быст...</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   product_id  category_id shop_title  rating  \\\n",
       "0      325286        12171      Aksik     5.0   \n",
       "\n",
       "                                               title  \\\n",
       "0  Зарядный кабель Borofone BX1 Lightning для айф...   \n",
       "\n",
       "                                         description  \\\n",
       "0  Зарядный кабель Borofone BX1 подходит для заря...   \n",
       "\n",
       "                                          attributes  train  valid   test  \n",
       "0  Длина: 1м. Разъем: Lightning. Подерживает быст...   True  False  False  "
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_fr.head(1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's now add labels for rare `category ids`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>product_id</th>\n",
       "      <th>category_id</th>\n",
       "      <th>shop_title</th>\n",
       "      <th>rating</th>\n",
       "      <th>title</th>\n",
       "      <th>description</th>\n",
       "      <th>attributes</th>\n",
       "      <th>train</th>\n",
       "      <th>valid</th>\n",
       "      <th>test</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>831567</td>\n",
       "      <td>11549</td>\n",
       "      <td>SOFIA MUM</td>\n",
       "      <td>4.5</td>\n",
       "      <td>Толстовка утепленная для беременных и кормящих...</td>\n",
       "      <td>Невероятно теплая и уютная толстовка выполнена...</td>\n",
       "      <td>на каждый день. большие размеры. для беременны...</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    product_id  category_id shop_title  rating  \\\n",
       "18      831567        11549  SOFIA MUM     4.5   \n",
       "\n",
       "                                                title  \\\n",
       "18  Толстовка утепленная для беременных и кормящих...   \n",
       "\n",
       "                                          description  \\\n",
       "18  Невероятно теплая и уютная толстовка выполнена...   \n",
       "\n",
       "                                           attributes  train  valid   test  \n",
       "18  на каждый день. большие размеры. для беременны...   True  False  False  "
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rare_categories_ids = categories_frequences[rare_categories].index\n",
    "dataset_rare = dataset[dataset['category_id'].isin(rare_categories_ids)]\n",
    "\n",
    "size = dataset_rare.shape[0]\n",
    "train = [True] * size\n",
    "valid = [False] * size\n",
    "test = [False] * size\n",
    "\n",
    "rare_separation = pd.DataFrame({'train': train, 'valid': valid, 'test': test})\n",
    "dataset_rare = pd.concat(\n",
    "    [\n",
    "        dataset_rare.reset_index(drop=True), \n",
    "        rare_separation.reset_index(drop=True)\n",
    "    ], \n",
    "    axis=1\n",
    ")\n",
    "dataset_rare.sample(1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can assemble all the data back."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_splitted = pd.concat([\n",
    "    dataset_fr.reset_index(drop=True),\n",
    "    dataset_rare.reset_index(drop=True)\n",
    "])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we have orginal shape of splitted data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(91120, 10)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_splitted.shape"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's now save this dataset for future experements to have the same data separation for all the models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_splitted['attributes'].fillna('', inplace=True)\n",
    "dataset_splitted['description'].fillna('', inplace=True)\n",
    "dataset_splitted.to_csv('dataset.csv', index=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Baseline: FastText + MLP"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>product_id</th>\n",
       "      <th>category_id</th>\n",
       "      <th>shop_title</th>\n",
       "      <th>rating</th>\n",
       "      <th>title</th>\n",
       "      <th>description</th>\n",
       "      <th>attributes</th>\n",
       "      <th>train</th>\n",
       "      <th>valid</th>\n",
       "      <th>test</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>325286</td>\n",
       "      <td>12171</td>\n",
       "      <td>Aksik</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Зарядный кабель Borofone BX1 Lightning для айф...</td>\n",
       "      <td>Зарядный кабель Borofone BX1 подходит для заря...</td>\n",
       "      <td>Длина: 1м. Разъем: Lightning. Подерживает быст...</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   product_id  category_id shop_title  rating  \\\n",
       "0      325286        12171      Aksik     5.0   \n",
       "\n",
       "                                               title  \\\n",
       "0  Зарядный кабель Borofone BX1 Lightning для айф...   \n",
       "\n",
       "                                         description  \\\n",
       "0  Зарядный кабель Borofone BX1 подходит для заря...   \n",
       "\n",
       "                                          attributes  train  valid   test  \n",
       "0  Длина: 1м. Разъем: Lightning. Подерживает быст...   True  False  False  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = pd.read_csv('dataset.csv')\n",
    "dataset.head(1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Embeddings"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's now create embeddings for products' titles, descriptions and attributes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning : `load_model` does not return WordVectorModel or SupervisedModel any more, but a `FastText` object which is very similar.\n",
      "100%|██████████| 91120/91120 [14:49<00:00, 102.48it/s]\n",
      "Warning : `load_model` does not return WordVectorModel or SupervisedModel any more, but a `FastText` object which is very similar.\n",
      "100%|██████████| 91120/91120 [1:15:15<00:00, 20.18it/s]\n",
      "Warning : `load_model` does not return WordVectorModel or SupervisedModel any more, but a `FastText` object which is very similar.\n",
      "100%|██████████| 91120/91120 [22:18<00:00, 68.07it/s] \n"
     ]
    }
   ],
   "source": [
    "title_emb = get_embeddings(dataset, 'title', file_name='title')\n",
    "description_emb = get_embeddings(dataset, 'description', file_name='description')\n",
    "attributes_emb = get_embeddings(dataset, 'attributes', file_name='attributes')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "title_emb = np.load('./embeddings/title.npy')\n",
    "description_emb = np.load('./embeddings/description.npy')\n",
    "attributes_emb = np.load('./embeddings/attributes.npy')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I will train baseline model on concatenated embeddings of three text columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "emb = np.concatenate([title_emb, description_emb, attributes_emb], axis=1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loaders"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here I convert category ids into indexes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels, index_to_id, id_to_index = create_labels(dataset.category_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader, valid_loader, test_loader = get_loaders(dataset, emb, 'category_id', batch_size=1024)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I will use simlpe two layer FCNN as baseline model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_size = 900\n",
    "hid_size = 100\n",
    "num_classes = len(index_to_id)\n",
    "\n",
    "model = nn.Sequential(\n",
    "    nn.Linear(input_size, hid_size),\n",
    "    nn.BatchNorm1d(hid_size),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(hid_size, hid_size),\n",
    "    nn.BatchNorm1d(hid_size),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(hid_size, num_classes)\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I train the model with use of early stopping technique. I save checkpoint which shows the best result in validation set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 1\n",
      "Loader: train. f1 score: 0.2349\n",
      "Loader: valid. f1 score: 0.3322\n",
      "\n",
      "Epoch: 2\n",
      "Loader: train. f1 score: 0.4266\n",
      "Loader: valid. f1 score: 0.5024\n",
      "\n",
      "Epoch: 3\n",
      "Loader: train. f1 score: 0.5706\n",
      "Loader: valid. f1 score: 0.6276\n",
      "\n",
      "Epoch: 4\n",
      "Loader: train. f1 score: 0.6778\n",
      "Loader: valid. f1 score: 0.7033\n",
      "\n",
      "Epoch: 5\n",
      "Loader: train. f1 score: 0.7455\n",
      "Loader: valid. f1 score: 0.7462\n",
      "\n",
      "Epoch: 6\n",
      "Loader: train. f1 score: 0.7893\n",
      "Loader: valid. f1 score: 0.7706\n",
      "\n",
      "Epoch: 7\n",
      "Loader: train. f1 score: 0.821\n",
      "Loader: valid. f1 score: 0.7836\n",
      "\n",
      "Epoch: 8\n",
      "Loader: train. f1 score: 0.8502\n",
      "Loader: valid. f1 score: 0.7951\n",
      "\n",
      "Epoch: 9\n",
      "Loader: train. f1 score: 0.8586\n",
      "Loader: valid. f1 score: 0.7977\n",
      "\n",
      "Epoch: 10\n",
      "Loader: train. f1 score: 0.8615\n",
      "Loader: valid. f1 score: 0.7986\n",
      "\n",
      "Epoch: 11\n",
      "Loader: train. f1 score: 0.8645\n",
      "Loader: valid. f1 score: 0.8007\n",
      "\n",
      "Epoch: 12\n",
      "Loader: train. f1 score: 0.8676\n",
      "Loader: valid. f1 score: 0.8014\n",
      "\n",
      "Epoch: 13\n",
      "Loader: train. f1 score: 0.8696\n",
      "Loader: valid. f1 score: 0.8025\n",
      "\n",
      "Epoch: 14\n",
      "Loader: train. f1 score: 0.8716\n",
      "Loader: valid. f1 score: 0.8062\n",
      "\n",
      "Epoch: 15\n",
      "Loader: train. f1 score: 0.8766\n",
      "Loader: valid. f1 score: 0.804\n",
      "\n",
      "Epoch: 16\n",
      "Loader: train. f1 score: 0.8766\n",
      "Loader: valid. f1 score: 0.8035\n",
      "\n",
      "Epoch: 17\n",
      "Loader: train. f1 score: 0.8771\n",
      "Loader: valid. f1 score: 0.8044\n",
      "\n",
      "Epoch: 18\n",
      "Loader: train. f1 score: 0.8775\n",
      "Loader: valid. f1 score: 0.8038\n",
      "\n",
      "Epoch: 19\n",
      "Loader: train. f1 score: 0.8778\n",
      "Loader: valid. f1 score: 0.8041\n",
      "\n",
      "Epoch: 20\n",
      "Loader: train. f1 score: 0.8772\n",
      "Loader: valid. f1 score: 0.805\n",
      "\n",
      "Epoch: 21\n",
      "Loader: train. f1 score: 0.8787\n",
      "Loader: valid. f1 score: 0.8036\n",
      "\n",
      "Epoch: 22\n",
      "Loader: train. f1 score: 0.8784\n",
      "Loader: valid. f1 score: 0.805\n",
      "\n",
      "Epoch: 23\n",
      "Loader: train. f1 score: 0.878\n",
      "Loader: valid. f1 score: 0.805\n",
      "\n",
      "Epoch: 24\n",
      "Loader: train. f1 score: 0.8787\n",
      "Loader: valid. f1 score: 0.8054\n",
      "\n",
      "Epoch: 25\n",
      "Loader: train. f1 score: 0.8787\n",
      "Loader: valid. f1 score: 0.8046\n",
      "\n",
      "Epoch: 26\n",
      "Loader: train. f1 score: 0.8786\n",
      "Loader: valid. f1 score: 0.8053\n",
      "\n",
      "Epoch: 27\n",
      "Loader: train. f1 score: 0.8785\n",
      "Loader: valid. f1 score: 0.804\n",
      "\n",
      "Epoch: 28\n",
      "Loader: train. f1 score: 0.8784\n",
      "Loader: valid. f1 score: 0.8043\n",
      "\n",
      "Epoch: 29\n",
      "Loader: train. f1 score: 0.8792\n",
      "Loader: valid. f1 score: 0.8048\n",
      "\n",
      "Epoch: 30\n",
      "Loader: train. f1 score: 0.8785\n",
      "Loader: valid. f1 score: 0.8047\n",
      "\n",
      "Best f1 score:\n",
      "\n",
      "train: 0.8792\n",
      "valid: 0.8062\n"
     ]
    }
   ],
   "source": [
    "acc_train, acc_test = train_model(\n",
    "    model, \n",
    "    'baseline', \n",
    "    train_loader, \n",
    "    valid_loader, \n",
    "    num_epochs=30, \n",
    "    print_res=True\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see the model is being overfit quite a lot."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's finally count performance of baseline model on test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8303200669101575"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_true, y_pred = test_model(model, test_loader)\n",
    "\n",
    "f1_score(y_pred, y_true, average='weighted')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Also I decided to test the performance of each column separately. I trained model separately on `titles`, `descriptions` and `attributes`.\n",
    "\n",
    "I deleted sells with training and so forth. Here the results"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Title:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8038047745902039"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_true, y_pred = test_model(model, test_loader)\n",
    "\n",
    "f1_score(y_pred, y_true, average='weighted')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Description:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7110509801380898"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_true, y_pred = test_model(model, test_loader)\n",
    "\n",
    "f1_score(y_pred, y_true, average='weighted')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Attributes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7181879317233768"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_true, y_pred = test_model(model, test_loader)\n",
    "\n",
    "f1_score(y_pred, y_true, average='weighted')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can observe `title` column is most informative. It gives almost the same result as all the three columns combined: **0.803** vs **0.83**."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bert + MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.read_csv('dataset.csv')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Embeddings"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I will take sentence embeddings from `sberbank-ai/ruRoberta-large` model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_len = max(dataset['title'].apply(lambda s: len(s.split())))\n",
    "title_embeddings_bert = make_features_transformers(dataset, 'title', max_len, 'title_embeddings_bert')\n",
    "\n",
    "dataset['description'].fillna('', inplace=True)\n",
    "max_len = int(dataset['description'].apply(lambda s: len(s.split())).mean())\n",
    "description_embeddings_bert = make_features_transformers(dataset, 'description', max_len, 'description_embeddings_bert')\n",
    "\n",
    "dataset['attributes'].fillna('', inplace=True)\n",
    "max_len = max(dataset['attributes'].apply(lambda s: len(s.split())))\n",
    "attributes_embeddings_bert = make_features_transformers(dataset, 'attributes', max_len, 'attributes_embeddings_bert')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's try only title embeddings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 1\n",
      "Loader: train. f1 score: 0.2262\n",
      "Loader: valid. f1 score: 0.3213\n",
      "\n",
      "Epoch: 2\n",
      "Loader: train. f1 score: 0.4145\n",
      "Loader: valid. f1 score: 0.4932\n",
      "\n",
      "Epoch: 3\n",
      "Loader: train. f1 score: 0.5557\n",
      "Loader: valid. f1 score: 0.6103\n",
      "\n",
      "Epoch: 4\n",
      "Loader: train. f1 score: 0.6556\n",
      "Loader: valid. f1 score: 0.6759\n",
      "\n",
      "Epoch: 5\n",
      "Loader: train. f1 score: 0.7202\n",
      "Loader: valid. f1 score: 0.7138\n",
      "\n",
      "Epoch: 6\n",
      "Loader: train. f1 score: 0.7664\n",
      "Loader: valid. f1 score: 0.7493\n",
      "\n",
      "Epoch: 7\n",
      "Loader: train. f1 score: 0.7969\n",
      "Loader: valid. f1 score: 0.7627\n",
      "\n",
      "Epoch: 8\n",
      "Loader: train. f1 score: 0.8324\n",
      "Loader: valid. f1 score: 0.7822\n",
      "\n",
      "Epoch: 9\n",
      "Loader: train. f1 score: 0.8404\n",
      "Loader: valid. f1 score: 0.7838\n",
      "\n",
      "Epoch: 10\n",
      "Loader: train. f1 score: 0.8443\n",
      "Loader: valid. f1 score: 0.7854\n",
      "\n",
      "Epoch: 11\n",
      "Loader: train. f1 score: 0.8468\n",
      "Loader: valid. f1 score: 0.7884\n",
      "\n",
      "Epoch: 12\n",
      "Loader: train. f1 score: 0.8498\n",
      "Loader: valid. f1 score: 0.7891\n",
      "\n",
      "Epoch: 13\n",
      "Loader: train. f1 score: 0.8521\n",
      "Loader: valid. f1 score: 0.7889\n",
      "\n",
      "Epoch: 14\n",
      "Loader: train. f1 score: 0.8551\n",
      "Loader: valid. f1 score: 0.7901\n",
      "\n",
      "Epoch: 15\n",
      "Loader: train. f1 score: 0.8599\n",
      "Loader: valid. f1 score: 0.7903\n",
      "\n",
      "Epoch: 16\n",
      "Loader: train. f1 score: 0.8603\n",
      "Loader: valid. f1 score: 0.7907\n",
      "\n",
      "Epoch: 17\n",
      "Loader: train. f1 score: 0.8598\n",
      "Loader: valid. f1 score: 0.7907\n",
      "\n",
      "Epoch: 18\n",
      "Loader: train. f1 score: 0.8601\n",
      "Loader: valid. f1 score: 0.7902\n",
      "\n",
      "Epoch: 19\n",
      "Loader: train. f1 score: 0.8606\n",
      "Loader: valid. f1 score: 0.7905\n",
      "\n",
      "Epoch: 20\n",
      "Loader: train. f1 score: 0.8615\n",
      "Loader: valid. f1 score: 0.792\n",
      "\n",
      "Epoch: 21\n",
      "Loader: train. f1 score: 0.8613\n",
      "Loader: valid. f1 score: 0.7913\n",
      "\n",
      "Epoch: 22\n",
      "Loader: train. f1 score: 0.8621\n",
      "Loader: valid. f1 score: 0.7911\n",
      "\n",
      "Epoch: 23\n",
      "Loader: train. f1 score: 0.862\n",
      "Loader: valid. f1 score: 0.7913\n",
      "\n",
      "Epoch: 24\n",
      "Loader: train. f1 score: 0.862\n",
      "Loader: valid. f1 score: 0.7917\n",
      "\n",
      "Epoch: 25\n",
      "Loader: train. f1 score: 0.8621\n",
      "Loader: valid. f1 score: 0.791\n",
      "\n",
      "Epoch: 26\n",
      "Loader: train. f1 score: 0.8622\n",
      "Loader: valid. f1 score: 0.7909\n",
      "\n",
      "Epoch: 27\n",
      "Loader: train. f1 score: 0.8623\n",
      "Loader: valid. f1 score: 0.7914\n",
      "\n",
      "Epoch: 28\n",
      "Loader: train. f1 score: 0.8626\n",
      "Loader: valid. f1 score: 0.791\n",
      "\n",
      "Epoch: 29\n",
      "Loader: train. f1 score: 0.8622\n",
      "Loader: valid. f1 score: 0.7907\n",
      "\n",
      "Epoch: 30\n",
      "Loader: train. f1 score: 0.8618\n",
      "Loader: valid. f1 score: 0.7917\n",
      "\n",
      "Best f1 score:\n",
      "\n",
      "train: 0.8626\n",
      "valid: 0.792\n",
      "\n",
      "Test f1 score: 0.818\n"
     ]
    }
   ],
   "source": [
    "emb = np.load('./embeddings/title_embeddings_bert.npy')\n",
    "emb = emb.astype(np.double)\n",
    "\n",
    "ad_hoc_train(emb, 'bert_mlp_titile')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 1\n",
      "Loader: train. f1 score: 0.2188\n",
      "Loader: valid. f1 score: 0.3084\n",
      "\n",
      "Epoch: 2\n",
      "Loader: train. f1 score: 0.4104\n",
      "Loader: valid. f1 score: 0.4872\n",
      "\n",
      "Epoch: 3\n",
      "Loader: train. f1 score: 0.5632\n",
      "Loader: valid. f1 score: 0.6096\n",
      "\n",
      "Epoch: 4\n",
      "Loader: train. f1 score: 0.675\n",
      "Loader: valid. f1 score: 0.6857\n",
      "\n",
      "Epoch: 5\n",
      "Loader: train. f1 score: 0.7478\n",
      "Loader: valid. f1 score: 0.7378\n",
      "\n",
      "Epoch: 6\n",
      "Loader: train. f1 score: 0.8016\n",
      "Loader: valid. f1 score: 0.7695\n",
      "\n",
      "Epoch: 7\n",
      "Loader: train. f1 score: 0.8368\n",
      "Loader: valid. f1 score: 0.7845\n",
      "\n",
      "Epoch: 8\n",
      "Loader: train. f1 score: 0.8744\n",
      "Loader: valid. f1 score: 0.808\n",
      "\n",
      "Epoch: 9\n",
      "Loader: train. f1 score: 0.8837\n",
      "Loader: valid. f1 score: 0.812\n",
      "\n",
      "Epoch: 10\n",
      "Loader: train. f1 score: 0.8879\n",
      "Loader: valid. f1 score: 0.8123\n",
      "\n",
      "Epoch: 11\n",
      "Loader: train. f1 score: 0.8919\n",
      "Loader: valid. f1 score: 0.812\n",
      "\n",
      "Epoch: 12\n",
      "Loader: train. f1 score: 0.8952\n",
      "Loader: valid. f1 score: 0.8121\n",
      "\n",
      "Epoch: 13\n",
      "Loader: train. f1 score: 0.8998\n",
      "Loader: valid. f1 score: 0.8149\n",
      "\n",
      "Epoch: 14\n",
      "Loader: train. f1 score: 0.9026\n",
      "Loader: valid. f1 score: 0.8144\n",
      "\n",
      "Epoch: 15\n",
      "Loader: train. f1 score: 0.9081\n",
      "Loader: valid. f1 score: 0.8154\n",
      "\n",
      "Epoch: 16\n",
      "Loader: train. f1 score: 0.9086\n",
      "Loader: valid. f1 score: 0.8154\n",
      "\n",
      "Epoch: 17\n",
      "Loader: train. f1 score: 0.9091\n",
      "Loader: valid. f1 score: 0.8159\n",
      "\n",
      "Epoch: 18\n",
      "Loader: train. f1 score: 0.9094\n",
      "Loader: valid. f1 score: 0.8163\n",
      "\n",
      "Epoch: 19\n",
      "Loader: train. f1 score: 0.9094\n",
      "Loader: valid. f1 score: 0.8175\n",
      "\n",
      "Epoch: 20\n",
      "Loader: train. f1 score: 0.9095\n",
      "Loader: valid. f1 score: 0.8165\n",
      "\n",
      "Epoch: 21\n",
      "Loader: train. f1 score: 0.9104\n",
      "Loader: valid. f1 score: 0.8171\n",
      "\n",
      "Epoch: 22\n",
      "Loader: train. f1 score: 0.9111\n",
      "Loader: valid. f1 score: 0.8171\n",
      "\n",
      "Epoch: 23\n",
      "Loader: train. f1 score: 0.9113\n",
      "Loader: valid. f1 score: 0.8171\n",
      "\n",
      "Epoch: 24\n",
      "Loader: train. f1 score: 0.9114\n",
      "Loader: valid. f1 score: 0.8175\n",
      "\n",
      "Epoch: 25\n",
      "Loader: train. f1 score: 0.9108\n",
      "Loader: valid. f1 score: 0.8175\n",
      "\n",
      "Epoch: 26\n",
      "Loader: train. f1 score: 0.9111\n",
      "Loader: valid. f1 score: 0.8176\n",
      "\n",
      "Epoch: 27\n",
      "Loader: train. f1 score: 0.9113\n",
      "Loader: valid. f1 score: 0.8176\n",
      "\n",
      "Epoch: 28\n",
      "Loader: train. f1 score: 0.911\n",
      "Loader: valid. f1 score: 0.8171\n",
      "\n",
      "Epoch: 29\n",
      "Loader: train. f1 score: 0.9116\n",
      "Loader: valid. f1 score: 0.8178\n",
      "\n",
      "Epoch: 30\n",
      "Loader: train. f1 score: 0.9111\n",
      "Loader: valid. f1 score: 0.8178\n",
      "\n",
      "Best f1 score:\n",
      "\n",
      "train: 0.9116\n",
      "valid: 0.8178\n",
      "\n",
      "Test f1 score: 0.839\n"
     ]
    }
   ],
   "source": [
    "title_emb = np.load('./embeddings/title_embeddings_bert.npy')\n",
    "description_emb = np.load('./embeddings/description_embeddings_bert.npy')\n",
    "attributes_emb = np.load('./embeddings/attributes_embeddings_bert.npy')\n",
    "emb = np.concatenate([title_emb, description_emb, attributes_emb], axis=1)\n",
    "emb = emb.astype(np.double)\n",
    "\n",
    "ad_hoc_train(emb, 'bert_mlp_titile_description_attributes')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This result of `0.839` is a bit better than baseline with score `0.83`."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Working with images"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At first I want to try pretrained on ImageNet models from **torchvision**. I chose the best one in terms of accuracy and computational power that it needs. I will usw `resnet50` to extract feature maps from the images and use them for future classification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.read_csv('./dataset.csv')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generating feature maps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images_embeddings =  make_features_cnn(dataset, 'product_id', './images/train', 'resnet50_embeddings')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 1\n",
      "Loader: train. f1 score: 0.1466\n",
      "Loader: valid. f1 score: 0.1965\n",
      "\n",
      "Epoch: 2\n",
      "Loader: train. f1 score: 0.2556\n",
      "Loader: valid. f1 score: 0.2924\n",
      "\n",
      "Epoch: 3\n",
      "Loader: train. f1 score: 0.3336\n",
      "Loader: valid. f1 score: 0.3542\n",
      "\n",
      "Epoch: 4\n",
      "Loader: train. f1 score: 0.3922\n",
      "Loader: valid. f1 score: 0.3923\n",
      "\n",
      "Epoch: 5\n",
      "Loader: train. f1 score: 0.4406\n",
      "Loader: valid. f1 score: 0.4231\n",
      "\n",
      "Epoch: 6\n",
      "Loader: train. f1 score: 0.477\n",
      "Loader: valid. f1 score: 0.4424\n",
      "\n",
      "Epoch: 7\n",
      "Loader: train. f1 score: 0.5094\n",
      "Loader: valid. f1 score: 0.4575\n",
      "\n",
      "Epoch: 8\n",
      "Loader: train. f1 score: 0.5467\n",
      "Loader: valid. f1 score: 0.467\n",
      "\n",
      "Epoch: 9\n",
      "Loader: train. f1 score: 0.5563\n",
      "Loader: valid. f1 score: 0.4698\n",
      "\n",
      "Epoch: 10\n",
      "Loader: train. f1 score: 0.5623\n",
      "Loader: valid. f1 score: 0.4732\n",
      "\n",
      "Epoch: 11\n",
      "Loader: train. f1 score: 0.5655\n",
      "Loader: valid. f1 score: 0.4737\n",
      "\n",
      "Epoch: 12\n",
      "Loader: train. f1 score: 0.5688\n",
      "Loader: valid. f1 score: 0.475\n",
      "\n",
      "Epoch: 13\n",
      "Loader: train. f1 score: 0.5724\n",
      "Loader: valid. f1 score: 0.4764\n",
      "\n",
      "Epoch: 14\n",
      "Loader: train. f1 score: 0.5761\n",
      "Loader: valid. f1 score: 0.4768\n",
      "\n",
      "Epoch: 15\n",
      "Loader: train. f1 score: 0.5813\n",
      "Loader: valid. f1 score: 0.4766\n",
      "\n",
      "Epoch: 16\n",
      "Loader: train. f1 score: 0.582\n",
      "Loader: valid. f1 score: 0.4769\n",
      "\n",
      "Epoch: 17\n",
      "Loader: train. f1 score: 0.5824\n",
      "Loader: valid. f1 score: 0.4782\n",
      "\n",
      "Epoch: 18\n",
      "Loader: train. f1 score: 0.5822\n",
      "Loader: valid. f1 score: 0.4785\n",
      "\n",
      "Epoch: 19\n",
      "Loader: train. f1 score: 0.5823\n",
      "Loader: valid. f1 score: 0.4767\n",
      "\n",
      "Epoch: 20\n",
      "Loader: train. f1 score: 0.5832\n",
      "Loader: valid. f1 score: 0.4777\n",
      "\n",
      "Epoch: 21\n",
      "Loader: train. f1 score: 0.5838\n",
      "Loader: valid. f1 score: 0.4783\n",
      "\n",
      "Epoch: 22\n",
      "Loader: train. f1 score: 0.584\n",
      "Loader: valid. f1 score: 0.4777\n",
      "\n",
      "Epoch: 23\n",
      "Loader: train. f1 score: 0.5843\n",
      "Loader: valid. f1 score: 0.4778\n",
      "\n",
      "Epoch: 24\n",
      "Loader: train. f1 score: 0.5841\n",
      "Loader: valid. f1 score: 0.4782\n",
      "\n",
      "Epoch: 25\n",
      "Loader: train. f1 score: 0.5837\n",
      "Loader: valid. f1 score: 0.4774\n",
      "\n",
      "Epoch: 26\n",
      "Loader: train. f1 score: 0.5844\n",
      "Loader: valid. f1 score: 0.4778\n",
      "\n",
      "Epoch: 27\n",
      "Loader: train. f1 score: 0.5842\n",
      "Loader: valid. f1 score: 0.4778\n",
      "\n",
      "Epoch: 28\n",
      "Loader: train. f1 score: 0.5847\n",
      "Loader: valid. f1 score: 0.4781\n",
      "\n",
      "Epoch: 29\n",
      "Loader: train. f1 score: 0.5842\n",
      "Loader: valid. f1 score: 0.4773\n",
      "\n",
      "Epoch: 30\n",
      "Loader: train. f1 score: 0.5844\n",
      "Loader: valid. f1 score: 0.4772\n",
      "\n",
      "Best f1 score:\n",
      "\n",
      "train: 0.5847\n",
      "valid: 0.4785\n",
      "\n",
      "Test f1 score: 0.552\n"
     ]
    }
   ],
   "source": [
    "img_emb = np.load(\"./embeddings/images_embeddings.npy\")\n",
    "img_emb = img_emb.astype(np.double)\n",
    "ad_hoc_train(img_emb, 'images_only')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see just images embeddings from not fine tuned model are not very informative in predictions but they can probably help in combination with other features."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Wikipedia2Vec"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here I decided to generate embeddings from `Wikipedia2Vec` model trained on Russian Wikipedia."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.read_csv(\"dataset.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "title_emb_wiki = get_embeddings(dataset, 'title', file_name='title_wiki', use_wiki2vec=True, use_fasttext=False)\n",
    "description_emb_wiki = get_embeddings(dataset, 'description', file_name='description_wiki', use_wiki2vec=True, use_fasttext=False)\n",
    "attributes_emb_wiki = get_embeddings(dataset, 'attributes', file_name='attributes_wiki', use_wiki2vec=True, use_fasttext=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "title_emb_wiki = np.load('./embeddings/title_wiki.npy')\n",
    "description_emb_wiki = np.load('./embeddings/description_wiki.npy')\n",
    "attributes_emb_wiki = np.load('./embeddings/attributes_wiki.npy')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's evaluate title embeddings of wiki2vec."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 1\n",
      "Loader: train. f1 score: 0.2326\n",
      "Loader: valid. f1 score: 0.3287\n",
      "\n",
      "Epoch: 2\n",
      "Loader: train. f1 score: 0.4038\n",
      "Loader: valid. f1 score: 0.479\n",
      "\n",
      "Epoch: 3\n",
      "Loader: train. f1 score: 0.5382\n",
      "Loader: valid. f1 score: 0.5868\n",
      "\n",
      "Epoch: 4\n",
      "Loader: train. f1 score: 0.6252\n",
      "Loader: valid. f1 score: 0.6521\n",
      "\n",
      "Epoch: 5\n",
      "Loader: train. f1 score: 0.6828\n",
      "Loader: valid. f1 score: 0.6934\n",
      "\n",
      "Epoch: 6\n",
      "Loader: train. f1 score: 0.7243\n",
      "Loader: valid. f1 score: 0.7164\n",
      "\n",
      "Epoch: 7\n",
      "Loader: train. f1 score: 0.753\n",
      "Loader: valid. f1 score: 0.7348\n",
      "\n",
      "Epoch: 8\n",
      "Loader: train. f1 score: 0.7775\n",
      "Loader: valid. f1 score: 0.7438\n",
      "\n",
      "Epoch: 9\n",
      "Loader: train. f1 score: 0.7816\n",
      "Loader: valid. f1 score: 0.7467\n",
      "\n",
      "Epoch: 10\n",
      "Loader: train. f1 score: 0.7847\n",
      "Loader: valid. f1 score: 0.7469\n",
      "\n",
      "Epoch: 11\n",
      "Loader: train. f1 score: 0.7869\n",
      "Loader: valid. f1 score: 0.7489\n",
      "\n",
      "Epoch: 12\n",
      "Loader: train. f1 score: 0.7887\n",
      "Loader: valid. f1 score: 0.7521\n",
      "\n",
      "Epoch: 13\n",
      "Loader: train. f1 score: 0.7908\n",
      "Loader: valid. f1 score: 0.7513\n",
      "\n",
      "Epoch: 14\n",
      "Loader: train. f1 score: 0.7932\n",
      "Loader: valid. f1 score: 0.7533\n",
      "\n",
      "Epoch: 15\n",
      "Loader: train. f1 score: 0.7956\n",
      "Loader: valid. f1 score: 0.7529\n",
      "\n",
      "Epoch: 16\n",
      "Loader: train. f1 score: 0.7956\n",
      "Loader: valid. f1 score: 0.7522\n",
      "\n",
      "Epoch: 17\n",
      "Loader: train. f1 score: 0.7956\n",
      "Loader: valid. f1 score: 0.7532\n",
      "\n",
      "Epoch: 18\n",
      "Loader: train. f1 score: 0.7962\n",
      "Loader: valid. f1 score: 0.7535\n",
      "\n",
      "Epoch: 19\n",
      "Loader: train. f1 score: 0.7963\n",
      "Loader: valid. f1 score: 0.7536\n",
      "\n",
      "Epoch: 20\n",
      "Loader: train. f1 score: 0.797\n",
      "Loader: valid. f1 score: 0.7545\n",
      "\n",
      "Epoch: 21\n",
      "Loader: train. f1 score: 0.7974\n",
      "Loader: valid. f1 score: 0.7536\n",
      "\n",
      "Epoch: 22\n",
      "Loader: train. f1 score: 0.7973\n",
      "Loader: valid. f1 score: 0.7534\n",
      "\n",
      "Epoch: 23\n",
      "Loader: train. f1 score: 0.7975\n",
      "Loader: valid. f1 score: 0.7544\n",
      "\n",
      "Epoch: 24\n",
      "Loader: train. f1 score: 0.7969\n",
      "Loader: valid. f1 score: 0.7527\n",
      "\n",
      "Epoch: 25\n",
      "Loader: train. f1 score: 0.7974\n",
      "Loader: valid. f1 score: 0.7533\n",
      "\n",
      "Epoch: 26\n",
      "Loader: train. f1 score: 0.7974\n",
      "Loader: valid. f1 score: 0.7543\n",
      "\n",
      "Epoch: 27\n",
      "Loader: train. f1 score: 0.7975\n",
      "Loader: valid. f1 score: 0.7529\n",
      "\n",
      "Epoch: 28\n",
      "Loader: train. f1 score: 0.7969\n",
      "Loader: valid. f1 score: 0.7536\n",
      "\n",
      "Epoch: 29\n",
      "Loader: train. f1 score: 0.7971\n",
      "Loader: valid. f1 score: 0.7541\n",
      "\n",
      "Epoch: 30\n",
      "Loader: train. f1 score: 0.7973\n",
      "Loader: valid. f1 score: 0.7537\n",
      "\n",
      "Best f1 score:\n",
      "\n",
      "train: 0.7975\n",
      "valid: 0.7545\n",
      "\n",
      "Test f1 score: 0.779\n"
     ]
    }
   ],
   "source": [
    "ad_hoc_train(title_emb_wiki, 'title_wiki', num_epochs=30)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And finally have a look at combined wiki2vec embeddings from title, description and attributes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 1\n",
      "Loader: train. f1 score: 0.2385\n",
      "Loader: valid. f1 score: 0.3276\n",
      "\n",
      "Epoch: 2\n",
      "Loader: train. f1 score: 0.422\n",
      "Loader: valid. f1 score: 0.4997\n",
      "\n",
      "Epoch: 3\n",
      "Loader: train. f1 score: 0.5653\n",
      "Loader: valid. f1 score: 0.6087\n",
      "\n",
      "Epoch: 4\n",
      "Loader: train. f1 score: 0.6664\n",
      "Loader: valid. f1 score: 0.6825\n",
      "\n",
      "Epoch: 5\n",
      "Loader: train. f1 score: 0.732\n",
      "Loader: valid. f1 score: 0.7174\n",
      "\n",
      "Epoch: 6\n",
      "Loader: train. f1 score: 0.7779\n",
      "Loader: valid. f1 score: 0.7518\n",
      "\n",
      "Epoch: 7\n",
      "Loader: train. f1 score: 0.8102\n",
      "Loader: valid. f1 score: 0.7647\n",
      "\n",
      "Epoch: 8\n",
      "Loader: train. f1 score: 0.842\n",
      "Loader: valid. f1 score: 0.7795\n",
      "\n",
      "Epoch: 9\n",
      "Loader: train. f1 score: 0.8488\n",
      "Loader: valid. f1 score: 0.7817\n",
      "\n",
      "Epoch: 10\n",
      "Loader: train. f1 score: 0.8518\n",
      "Loader: valid. f1 score: 0.7829\n",
      "\n",
      "Epoch: 11\n",
      "Loader: train. f1 score: 0.8553\n",
      "Loader: valid. f1 score: 0.7836\n",
      "\n",
      "Epoch: 12\n",
      "Loader: train. f1 score: 0.858\n",
      "Loader: valid. f1 score: 0.7846\n",
      "\n",
      "Epoch: 13\n",
      "Loader: train. f1 score: 0.8602\n",
      "Loader: valid. f1 score: 0.7859\n",
      "\n",
      "Epoch: 14\n",
      "Loader: train. f1 score: 0.8629\n",
      "Loader: valid. f1 score: 0.7868\n",
      "\n",
      "Epoch: 15\n",
      "Loader: train. f1 score: 0.8672\n",
      "Loader: valid. f1 score: 0.788\n",
      "\n",
      "Epoch: 16\n",
      "Loader: train. f1 score: 0.8671\n",
      "Loader: valid. f1 score: 0.7871\n",
      "\n",
      "Epoch: 17\n",
      "Loader: train. f1 score: 0.8673\n",
      "Loader: valid. f1 score: 0.7883\n",
      "\n",
      "Epoch: 18\n",
      "Loader: train. f1 score: 0.8678\n",
      "Loader: valid. f1 score: 0.788\n",
      "\n",
      "Epoch: 19\n",
      "Loader: train. f1 score: 0.8679\n",
      "Loader: valid. f1 score: 0.7887\n",
      "\n",
      "Epoch: 20\n",
      "Loader: train. f1 score: 0.868\n",
      "Loader: valid. f1 score: 0.7875\n",
      "\n",
      "Epoch: 21\n",
      "Loader: train. f1 score: 0.8684\n",
      "Loader: valid. f1 score: 0.7877\n",
      "\n",
      "Epoch: 22\n",
      "Loader: train. f1 score: 0.8694\n",
      "Loader: valid. f1 score: 0.7879\n",
      "\n",
      "Epoch: 23\n",
      "Loader: train. f1 score: 0.8687\n",
      "Loader: valid. f1 score: 0.7882\n",
      "\n",
      "Epoch: 24\n",
      "Loader: train. f1 score: 0.8697\n",
      "Loader: valid. f1 score: 0.7882\n",
      "\n",
      "Epoch: 25\n",
      "Loader: train. f1 score: 0.8691\n",
      "Loader: valid. f1 score: 0.7881\n",
      "\n",
      "Epoch: 26\n",
      "Loader: train. f1 score: 0.8686\n",
      "Loader: valid. f1 score: 0.7881\n",
      "\n",
      "Epoch: 27\n",
      "Loader: train. f1 score: 0.8698\n",
      "Loader: valid. f1 score: 0.7877\n",
      "\n",
      "Epoch: 28\n",
      "Loader: train. f1 score: 0.8695\n",
      "Loader: valid. f1 score: 0.788\n",
      "\n",
      "Epoch: 29\n",
      "Loader: train. f1 score: 0.8691\n",
      "Loader: valid. f1 score: 0.7871\n",
      "\n",
      "Epoch: 30\n",
      "Loader: train. f1 score: 0.869\n",
      "Loader: valid. f1 score: 0.7881\n",
      "\n",
      "Best f1 score:\n",
      "\n",
      "train: 0.8698\n",
      "valid: 0.7887\n",
      "\n",
      "Test f1 score: 0.81\n"
     ]
    }
   ],
   "source": [
    "emb = np.concatenate([title_emb_wiki, description_emb_wiki, attributes_emb_wiki], axis=1)\n",
    "ad_hoc_train(emb, 'wiki', num_epochs=30)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Choosing best architecture and hyperparameters with `optuna`"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here I want to choose best combination of embddings and MLP architecture for this task.\n",
    "\n",
    "I will take all generated text and images embeddings and use optuna to find the best configuration."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = ['title', 'description', 'attributes']\n",
    "emb_types = ['fasttext', 'wiki', 'bert']\n",
    "\n",
    "emb = [np.load(f'./embeddings/{col}_{type}.npy') for col in cols for type in emb_types]\n",
    "emb.append(np.load('./embeddings/images.npy'))\n",
    "emb = np.concatenate(emb, axis=1)\n",
    "gc.collect()\n",
    "\n",
    "dataset = pd.read_csv('./dataset.csv')\n",
    "labels, index_to_id, id_to_index = create_labels(dataset.category_id)\n",
    "train_loader, valid_loader, test_loader = get_loaders(dataset, emb, 'category_id', batch_size=1024)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model architecture"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I will try different architectures from **0** to **3** `hidden layers`, from **10** to **1000** `neurons in these layers`, `batchnorm` or `dropout` to use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_size = emb.shape[1]\n",
    "emb = None\n",
    "gc.collect()\n",
    "\n",
    "num_classes = len(index_to_id)\n",
    "\n",
    "\n",
    "def define_model(trial):\n",
    "    n_layers = trial.suggest_int(\"num_layers\", 1, 3)\n",
    "    layers = []\n",
    "    in_features = input_size\n",
    "\n",
    "    if n_layers != 0:\n",
    "        model_type = trial.suggest_categorical(\"model_type\", [\"batchnorm\", \"dropout\"])\n",
    "\n",
    "        for i in range(n_layers):\n",
    "            out_features = trial.suggest_int(f\"num_neurons_layer_{i + 1}\", 10, 1000)\n",
    "            layers.append(nn.Linear(in_features, out_features))\n",
    "\n",
    "            if model_type == \"batchnorm\":\n",
    "                layers.append(nn.BatchNorm1d(out_features))\n",
    "\n",
    "            layers.append(nn.ReLU())\n",
    "\n",
    "            if model_type == \"dropout\":\n",
    "                p = trial.suggest_float(f\"dropout_layer_{i + 1}\", 0.2, 0.7)\n",
    "                layers.append(nn.Dropout(p))\n",
    "\n",
    "            in_features = out_features\n",
    "        \n",
    "    layers.append(nn.Linear(in_features, num_classes))\n",
    "\n",
    "    return nn.Sequential(*layers)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training method"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Also I will choose between four different `optimizers`, `learning rate` and `momentum` for them, and `step size` and `gamma` for `scheduler`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "\n",
    "def objective(trial):\n",
    "\n",
    "    model = define_model(trial)\n",
    "    model = model.to(device)\n",
    "    model.double()\n",
    "\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "    optimizer_name = trial.suggest_categorical(\"optimizer\", [\"AdamW\", \"SGD\", \"Adam\", \"RMSprop\"])\n",
    "\n",
    "    if optimizer_name == \"SGD\":\n",
    "        lr = trial.suggest_float(\"lr\", 0.1, 0.9, log=True)\n",
    "        momentum = trial.suggest_float(\"momentum\", 0.5, 0.999, log=True)\n",
    "        optimizer = getattr(optim, optimizer_name)(model.parameters(), lr=lr, momentum=momentum)\n",
    "    else:\n",
    "        lr = trial.suggest_float(\"lr\", 1e-5, 1e-1, log=True)\n",
    "        optimizer = getattr(optim, optimizer_name)(model.parameters(), lr=lr)\n",
    "\n",
    "    step_size = trial.suggest_int(\"scheduler_step_size\", 5, 20)\n",
    "    gamma = trial.suggest_float(\"scheduler_gamma\", 1e-2, 0.9, log=True)\n",
    "    scheduler = lr_scheduler.StepLR(optimizer, step_size=step_size, gamma=gamma)\n",
    "\n",
    "    loaders = {\"train\": train_loader, \"valid\": valid_loader}\n",
    "    f1 = {\"train\": [], \"valid\": []}\n",
    "    best_f1 = 0\n",
    "\n",
    "    num_epochs = 30\n",
    "\n",
    "    for epoch in tqdm(range(num_epochs)):\n",
    "        for k, dataloader in loaders.items():\n",
    "            epoch_preds = []\n",
    "            epoch_ys = []\n",
    "\n",
    "            for x_batch, y_batch in dataloader:\n",
    "\n",
    "                x_batch = x_batch.to(device)\n",
    "                y_batch = y_batch.to(device)\n",
    "\n",
    "                if k == \"train\":\n",
    "                    model.train()\n",
    "                    optimizer.zero_grad()\n",
    "                    outp = model(x_batch)\n",
    "                else:\n",
    "                    model.eval()\n",
    "                    with torch.no_grad():\n",
    "                        outp = model(x_batch)\n",
    "\n",
    "                preds = outp.argmax(-1)\n",
    "                epoch_preds += preds.tolist()\n",
    "                epoch_ys += y_batch.tolist()\n",
    "\n",
    "                if k == \"train\":\n",
    "                    loss = criterion(outp, y_batch)\n",
    "                    loss.backward()\n",
    "                    optimizer.step()\n",
    "\n",
    "            if k == 'train':\n",
    "                scheduler.step()\n",
    "\n",
    "            f1_epoch = f1_score(epoch_ys, epoch_preds, average='weighted')\n",
    "            f1[k].append(f1_epoch)\n",
    "            \n",
    "            if k == 'valid' and f1['valid'][-1] > best_f1:\n",
    "                best_f1 = f1['valid'][-1]\n",
    "\n",
    "            if k == 'valid':\n",
    "                trial.report(f1_epoch, epoch)\n",
    "                \n",
    "                if trial.should_prune():\n",
    "                    raise optuna.exceptions.TrialPruned()\n",
    "\n",
    "    return best_f1"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_trials = 150\n",
    "\n",
    "study = optuna.create_study(direction=\"maximize\")\n",
    "study.optimize(objective, n_trials=n_trials)\n",
    "\n",
    "pruned_trials = study.get_trials(deepcopy=False, states=[TrialState.PRUNED])\n",
    "complete_trials = study.get_trials(deepcopy=False, states=[TrialState.COMPLETE])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Best trial:\n",
      "  F1 Score:  0.8746192054507418\n",
      "\n",
      "  Params: \n",
      "    num_layers: 1\n",
      "    model_type: batchnorm\n",
      "    num_neurons_layer_1: 980\n",
      "    optimizer: AdamW\n",
      "    lr: 0.0006445724677322522\n",
      "    scheduler_step_size: 7\n",
      "    scheduler_gamma: 0.32015736506815595\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nBest trial:\")\n",
    "trial = study.best_trial\n",
    "print(\"  F1 Score: \", trial.value)\n",
    "print(\"\\n  Params: \")\n",
    "for key, value in trial.params.items():\n",
    "    print(\"    {}: {}\".format(key, value))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training the best model"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I've got \n",
    "\n",
    "```\n",
    "Train f1 score: 0.9999\n",
    "\n",
    "Valid f1 score: 0.8761\n",
    "\n",
    "Test f1 score: 0.883\n",
    "```\n",
    "\n",
    "for the best parameters obtained from optuna.\n",
    "\n",
    "Now I will train the best configuration on the whole dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = ['title', 'description', 'attributes']\n",
    "emb_types = ['fasttext', 'wiki', 'bert']\n",
    "\n",
    "emb = [np.load(f'./embeddings/{col}_{type}.npy') for col in cols for type in emb_types]\n",
    "emb.append(np.load('./embeddings/images.npy'))\n",
    "emb = np.concatenate(emb, axis=1)\n",
    "input_size = emb.shape[1]\n",
    "gc.collect()\n",
    "\n",
    "dataset = pd.read_csv('./dataset.csv')\n",
    "labels, index_to_id, id_to_index = create_labels(dataset['category_id'])\n",
    "\n",
    "dataloader = DataLoader(\n",
    "    list(zip(emb, labels)),\n",
    "    batch_size=1024, \n",
    "    num_workers=4,\n",
    "    shuffle=True, \n",
    "    drop_last=True\n",
    ")\n",
    "\n",
    "emb = None\n",
    "gc.collect()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I will use these dictionaries for predictions in the future."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('index_to_id.pkl', 'wb') as f:\n",
    "    pickle.dump(index_to_id, f)\n",
    "\n",
    "with open('id_to_index.pkl', 'wb') as f:\n",
    "    pickle.dump(id_to_index, f)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Best model architecture found by optuna."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden_size = 980\n",
    "num_classes = len(index_to_id)\n",
    "\n",
    "\n",
    "model = nn.Sequential(\n",
    "    nn.Linear(input_size, hidden_size),\n",
    "    nn.BatchNorm1d(hidden_size),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(hidden_size, num_classes)\n",
    ")  "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The best model is trained on the whole table with the best params found by **optuna** and saved as `best_params.pt`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Train f1 score: 0.9999\n"
     ]
    }
   ],
   "source": [
    "train_parametrized(\n",
    "    model,\n",
    "    model_name='best_params',\n",
    "    dataloader=dataloader,\n",
    "    num_epochs=15,\n",
    "    optimizer=torch.optim.AdamW,\n",
    "    lr=0.0006445724677322522,\n",
    "    step_size=7,\n",
    "    gamma=0.32015736506815595\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test data prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>product_id</th>\n",
       "      <th>sale</th>\n",
       "      <th>shop_id</th>\n",
       "      <th>shop_title</th>\n",
       "      <th>rating</th>\n",
       "      <th>text_fields</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1997646</td>\n",
       "      <td>False</td>\n",
       "      <td>22758</td>\n",
       "      <td>Sky_Electronics</td>\n",
       "      <td>5.0</td>\n",
       "      <td>{\"title\": \"Светодиодная лента Smart led Strip ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   product_id   sale  shop_id       shop_title  rating  \\\n",
       "1     1997646  False    22758  Sky_Electronics     5.0   \n",
       "\n",
       "                                         text_fields  \n",
       "1  {\"title\": \"Светодиодная лента Smart led Strip ...  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df = pd.read_parquet('./test.parquet')\n",
    "test_df.head(1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocess"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's extract `title`, `description` and `attributes` from the `text_fields` column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>description</th>\n",
       "      <th>attributes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Светодиодная лента Smart led Strip Light, с пу...</td>\n",
       "      <td>Светодиодная лента LED, 5 м, RGB (Цветная) вла...</td>\n",
       "      <td>Легкость управления с пульта, а так же смартфо...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title  \\\n",
       "0  Светодиодная лента Smart led Strip Light, с пу...   \n",
       "\n",
       "                                         description  \\\n",
       "0  Светодиодная лента LED, 5 м, RGB (Цветная) вла...   \n",
       "\n",
       "                                          attributes  \n",
       "0  Легкость управления с пульта, а так же смартфо...  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def extract_text(text_field: str):\n",
    "    content_dict = ast.literal_eval(text_field)\n",
    "    title = content_dict['title']\n",
    "    description = re.sub(\"<[^\\>]*>\", '', content_dict['description'])\n",
    "    attributes = '. '.join(content_dict['attributes'])\n",
    "\n",
    "    return title, description, attributes\n",
    "\n",
    "\n",
    "titles, desciptions, attributes = zip(*test_df['text_fields'].apply(extract_text))\n",
    "text_data = pd.DataFrame({'title': titles, 'description': desciptions, 'attributes': attributes})\n",
    "text_data.head(1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let' concatenate `title`, `description` and `attributes` with the corresponding `product_id`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>product_id</th>\n",
       "      <th>title</th>\n",
       "      <th>description</th>\n",
       "      <th>attributes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1997646</td>\n",
       "      <td>Светодиодная лента Smart led Strip Light, с пу...</td>\n",
       "      <td>Светодиодная лента LED, 5 м, RGB (Цветная) вла...</td>\n",
       "      <td>Легкость управления с пульта, а так же смартфо...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   product_id                                              title  \\\n",
       "0     1997646  Светодиодная лента Smart led Strip Light, с пу...   \n",
       "\n",
       "                                         description  \\\n",
       "0  Светодиодная лента LED, 5 м, RGB (Цветная) вла...   \n",
       "\n",
       "                                          attributes  \n",
       "0  Легкость управления с пульта, а так же смартфо...  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df = pd.concat(\n",
    "    [\n",
    "        test_df[['product_id']].reset_index(drop=True), \n",
    "        text_data.reset_index(drop=True)\n",
    "    ], \n",
    "    axis=1\n",
    ")\n",
    "test_df.head(1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Embeddings"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fasttext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning : `load_model` does not return WordVectorModel or SupervisedModel any more, but a `FastText` object which is very similar.\n",
      "100%|██████████| 16860/16860 [03:40<00:00, 76.38it/s] \n",
      "Warning : `load_model` does not return WordVectorModel or SupervisedModel any more, but a `FastText` object which is very similar.\n",
      "100%|██████████| 16860/16860 [15:41<00:00, 17.91it/s]\n",
      "Warning : `load_model` does not return WordVectorModel or SupervisedModel any more, but a `FastText` object which is very similar.\n",
      "100%|██████████| 16860/16860 [05:05<00:00, 55.12it/s] \n"
     ]
    }
   ],
   "source": [
    "title_emb = get_embeddings(\n",
    "    df=test_df,\n",
    "    column_name='title', \n",
    "    file_name='title_fasttext', \n",
    "    folder='embeddings_test', \n",
    "    use_fasttext=True, \n",
    "    use_wiki2vec=False\n",
    ")\n",
    "description_emb = get_embeddings(\n",
    "    df=test_df, \n",
    "    column_name='description', \n",
    "    file_name='description_fasttext', \n",
    "    folder='embeddings_test', \n",
    "    use_fasttext=True, \n",
    "    use_wiki2vec=False\n",
    ")\n",
    "attributes_emb = get_embeddings(\n",
    "    df=test_df, \n",
    "    column_name='attributes',\n",
    "    file_name='attributes_fasttext', \n",
    "    folder='embeddings_test', \n",
    "    use_fasttext=True, \n",
    "    use_wiki2vec=False\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Wiki2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "title_emb = get_embeddings(\n",
    "    df=test_df,\n",
    "    column_name='title', \n",
    "    file_name='title_wiki', \n",
    "    folder='embeddings_test', \n",
    "    use_fasttext=False, \n",
    "    use_wiki2vec=True\n",
    ")\n",
    "description_emb = get_embeddings(\n",
    "    df=test_df, \n",
    "    column_name='description', \n",
    "    file_name='description_wiki', \n",
    "    folder='embeddings_test', \n",
    "    use_fasttext=False, \n",
    "    use_wiki2vec=True\n",
    ")\n",
    "attributes_emb = get_embeddings(\n",
    "    df=test_df, \n",
    "    column_name='attributes',\n",
    "    file_name='attributes_wiki', \n",
    "    folder='embeddings_test', \n",
    "    use_fasttext=False, \n",
    "    use_wiki2vec=True\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_len = max(test_df['title'].apply(lambda s: len(s.split())))\n",
    "title_embeddings_bert = make_features_transformers(\n",
    "    test_df, \n",
    "    'title', \n",
    "    max_len, \n",
    "    'title_bert', \n",
    "    folder='embeddings_test'\n",
    ")\n",
    "\n",
    "test_df['description'].fillna('', inplace=True)\n",
    "max_len = int(test_df['description'].apply(lambda s: len(s.split())).mean())\n",
    "description_embeddings_bert = make_features_transformers(\n",
    "    test_df, \n",
    "    'description', \n",
    "    max_len, \n",
    "    'description_bert', \n",
    "    folder='embeddings_test'\n",
    ")\n",
    "\n",
    "test_df['attributes'].fillna('', inplace=True)\n",
    "max_len = max(test_df['attributes'].apply(lambda s: len(s.split())))\n",
    "attributes_embeddings_bert = make_features_transformers(\n",
    "    test_df, \n",
    "    'attributes', \n",
    "    max_len, \n",
    "    'attributes_bert', \n",
    "    folder='embeddings_test'\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/andrey/anaconda3/lib/python3.8/site-packages/torchvision/models/_utils.py:135: UserWarning: Using 'weights' as positional parameter(s) is deprecated since 0.13 and will be removed in 0.15. Please use keyword parameter(s) instead.\n",
      "  warnings.warn(\n",
      "100%|██████████| 16860/16860 [17:31<00:00, 16.03it/s]\n"
     ]
    }
   ],
   "source": [
    "images_embeddings =  make_features_cnn(\n",
    "    df=test_df, \n",
    "    id_column='product_id',\n",
    "    images_directory='./images/test', \n",
    "    filename_to_save='images', \n",
    "    directory_to_save='./embeddings_test'\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = ['title', 'description', 'attributes']\n",
    "emb_types = ['fasttext', 'wiki', 'bert']\n",
    "\n",
    "emb = [np.load(f'./embeddings_test/{col}_{type}.npy') for col in cols for type in emb_types]\n",
    "emb.append(np.load('./embeddings_test/images.npy'))\n",
    "emb = np.concatenate(emb, axis=1)\n",
    "input_size = emb.shape[1]\n",
    "\n",
    "dataloader = DataLoader(\n",
    "    emb,\n",
    "    batch_size=1024, \n",
    "    num_workers=4,\n",
    "    shuffle=False, \n",
    "    drop_last=False\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./index_to_id.pkl', 'rb') as f:\n",
    "    index_to_id = pickle.load(f)\n",
    "\n",
    "hidden_size = 980\n",
    "num_classes = len(index_to_id)\n",
    "\n",
    "model = nn.Sequential(\n",
    "    nn.Linear(input_size, hidden_size),\n",
    "    nn.BatchNorm1d(hidden_size),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(hidden_size, num_classes)\n",
    ")\n",
    "model.load_state_dict(torch.load('./models/best_params.pt'))\n",
    "model.double()\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>product_id</th>\n",
       "      <th>predicted_category_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1997646</td>\n",
       "      <td>13083</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>927375</td>\n",
       "      <td>14922</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1921513</td>\n",
       "      <td>2803</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1668662</td>\n",
       "      <td>12524</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1467778</td>\n",
       "      <td>13887</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16855</th>\n",
       "      <td>1914264</td>\n",
       "      <td>11645</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16856</th>\n",
       "      <td>1310569</td>\n",
       "      <td>12357</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16857</th>\n",
       "      <td>978095</td>\n",
       "      <td>13651</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16858</th>\n",
       "      <td>797547</td>\n",
       "      <td>2740</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16859</th>\n",
       "      <td>703835</td>\n",
       "      <td>11757</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>16860 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       product_id  predicted_category_id\n",
       "0         1997646                  13083\n",
       "1          927375                  14922\n",
       "2         1921513                   2803\n",
       "3         1668662                  12524\n",
       "4         1467778                  13887\n",
       "...           ...                    ...\n",
       "16855     1914264                  11645\n",
       "16856     1310569                  12357\n",
       "16857      978095                  13651\n",
       "16858      797547                   2740\n",
       "16859      703835                  11757\n",
       "\n",
       "[16860 rows x 2 columns]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions = predict(model, dataloader, index_to_id)\n",
    "predicted_df = pd.DataFrame({'product_id': test_df['product_id'], 'predicted_category_id': predictions})\n",
    "predicted_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_df.to_parquet('result.parquet')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Directions for further Research"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To increase the performane of the model in the future these techniques can be applied:\n",
    "* Feature Engineering: create dublicates of rare product categories, use more columns of the data, fine tune embeddings models on data.\n",
    "* Solve problems with CatBoost. It requires a lot of memory to perform well on these task.\n",
    "* Try to use [CLIP from OpenAI](https://habr.com/ru/amp/post/539312/)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
